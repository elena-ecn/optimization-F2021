{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project_1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPdZu6R62u0q37+1eTlKzpS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"gwmvsuizEqdN"},"source":["# Project 1: Gradient-based Algorithms and Differentiable Programming\n","\n","\n","## 1. Introduction\n","Consider a simple formulation of rocket landing where the rocket state $x(t)$ is represented by its distance to the ground $d(t)$ and its velocity $v(t)$, i.e., $x(t) = [d(t), v(t)]^T$, where $t$ specifies time. The control input of the rocket is its acceleration $a(t)$. The discrete-time dynamics follows \n","\n","$$\n","\\begin{aligned}\n","d(t+1) = d(t) + v(t) \\Delta t, \\\\\n","v(t+1) = v(t) + a(t) \\Delta t,\n","\\end{aligned}\n","$$\n","\n","where $\\Delta t$ is a time interval. Further, let the closed-loop controller be \n","\n","$$\n","a(t) = f_{\\theta}(x(t))\n","$$\n","\n","where $f_{\\theta}(\\cdot)$ is a neural network with parameters $\\theta$, which are to be determined through optimization.\n","\n","For each time step, we assign a loss as a function of the control input and the state: $l(x(t),a(t))$. In this example, we will simply set $l(x(t),a(t))=0$ for all $t=1,...,T-1$, where $T$ is the final time step, and $l(x(T),a(T)) = ||x(T)||^2 = d(T)^2 + v(T)^2$. This loss encourages the rocket to reach $d(T)=0$ and $v(T)=0$, which are proper landing conditions.\n","\n","The optimization problem is now formulated as\n","\n","$$\n","\\begin{aligned}\n","\\min_{\\theta} \\quad & ||x(T)||^2 \\\\\n","\\quad & d(t+1) = d(t) + v(t) \\Delta t, \\\\\n","\\quad & v(t+1) = v(t) + a(t) \\Delta t, \\\\\n","\\quad & a(t) = f_{\\theta}(x(t)), ~\\forall t=1,...,T-1\n","\\end{aligned}\n","$$\n","\n","While this problem is constrained, it is easy to see that the objective function can be expressed as a function of $x(T-1) and a(T-1)$, where $x(T-1)$ as a function of $x(T-2)$ and $a(T-2)$, and so on. Thus it is essentially an unconstrained problem with respect to $\\theta$. \n","\n","In the following, we code this problem up with [PyTorch](https://pytorch.org/), which allows us to only build the forward pass of the loss (i.e., how we move from $x(1)$ to $x(2)$ and all the way to $x(T)$) and automatically get the gradient $\\nabla_{\\theta} l(x(T),a(T))$.\n","\n","---\n","\n","## 2. A Better Problem Formulation\n","\n","Here is a list of things we discussed during the class that could help to make the problem more representative of the reality:\n","\n","1. More realistic definition of state and action spaces: Rocket orientation, angular velocity, etc. \n","2. Better dynamical model, e.g., drag\n","3. Constraints in state and action spaces\n","4. Controller design for a distribution of initial states rather than one\n","5. Randomness in dynamics, sensing, etc.\n","6. Discontinuity in modeling so that gradient cannot be computed, e.g., mechanical failures.\n","\n","In this project, please choose at least one aspect from 1 to 5 from the list to improve your problem formulation and solve the resultant problem. We will address 6 when we talk about reinforcement learning.\n","\n","Here is one example of problem formulation when we consider randomness in dynamics and initial states:\n","\n","$$\n","\\begin{aligned}\n","\\min_{\\theta} \\quad & \\mathbb{E}_{\\{w(t), u(t), x(0)\\}}\\left[||x(T)||^2\\right] \\\\\n","\\quad & d(t+1) = d(t) + v(t) + w(t) \\Delta t, \\\\\n","\\quad & v(t+1) = v(t) + a(t) + u(t) \\Delta t, \\\\\n","\\quad & a(t) = f_{\\theta}(x(t)), ~\\forall t=1,...,T-1 \\\\\n","\\quad & x(1) \\sim \\Pr(x(1))\n","\\end{aligned}\n","$$\n","\n","Here $w(t) \\sim \\Pr(w(t))$ and $u(t) \\sim \\Pr(u(t))$ are modeled as i.i.d. noises added to the dynamics, and $\\Pr(x(1))$ is the distribution of initial states. We will approximate this problem using samples from $\\Pr(w(t))$, $\\Pr(u(t))$, and $\\Pr(x(1))$. To do so, we sample $\\{w(1)^{(i)},w(2)^{(i)},...,w(T)^{(i)}\\}_{i}^N$ from $\\Pr(w(t))$,  $\\{u(1)^{(i)},u(2)^{(i)},...,u(T)^{(i)}\\}_{i}^N$ from $\\Pr(u(t))$, and $\\{x(0)^{(i)}\\}_{i}^N$ from $\\Pr(x(1))$, where $N$ is the number of samples to be considered. Then we have the following problem instead:\n","\n","$$\n","\\begin{aligned}\n","\\min_{\\theta} \\quad & \\frac{1}{N}\\sum_{i=1}^N ||x^{(i)}(T)||^2 \\\\\n","\\quad & d(t+1)^{(i)} = d(t)^{(i)} + v(t)^{(i)} + w(t)^{(i)} \\Delta t, \\\\\n","\\quad & v(t+1)^{(i)} = v(t)^{(i)} + a(t)^{(i)} + u(t)^{(i)} \\Delta t, \\\\\n","\\quad & a(t)^{(i)} = f_{\\theta}(x(t)^{(i)}), ~\\forall t=1,...,T-1, ~i=1,...,N \\\\\n","\\end{aligned}\n","$$\n","\n","The code up this new problem, you will fully utilize the tensor operations in PyTorch. For example, the state tensor \"x\" will now become a N-by-2 matrix, where the first dimension represents the number of trajectories to be optimized. \n","\n","## 3. Grading\n","\n","* (30%) Documentation of the problem formulation: Clearly describe the objective function, the variables, the constraints, and the assumptions involved in formulating the problem.\n","\n","* (40%) Programming: Like for homeworks, please push you code to your github repo. Please comment your code so that it is useful to you in the future.\n","\n","* (30%) Analysis of the results: Please document the convergence and the optimal solutions (e.g., the state trajectory if it is a control problem).\n","\n","* (Bonus 20%) Formulation of a problem different from rocket landing: The PyTorch framework can also be used for other engineering problems, e.g., for structure design with nonlinear mechanical properties. You get 20 bonus points for solving your own problems that are at least at the same level of difficulty as rocket landing. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1CefZrVWr6pkpHi8gpoh91V8599KPo7_v"},"id":"1Oy_jHCAEozE","executionInfo":{"status":"ok","timestamp":1634559102611,"user_tz":-180,"elapsed":66945,"user":{"displayName":"Elena Oikonomou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjieaR8SwyW3oT5Gj_-eTKl6SVjziMwjwjye6=s64","userId":"03571600125738632827"}},"outputId":"98446b21-2d07-4c96-a4aa-ce6fef7bfdad"},"source":["\"\"\"Optimization of a Controller for rocket landing with Neural Networks.\"\"\"\n","\n","import numpy as np\n","import torch as t\n","import torch.nn as nn\n","from torch import optim\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","\n","class Controller(nn.Module):\n","    \"\"\"NN Controller for rocket landing.\"\"\"\n","    def __init__(self, dim_input, dim_hidden, dim_output):\n","        \"\"\"\n","        Inputs:\n","          - dim_input(int):  # of system states\n","          - dim_output(int): # of actions\n","          - dim_hidden(int): # of hidden layer nodes\n","        \"\"\"\n","        super(Controller, self).__init__()\n","        self.network = nn.Sequential(\n","            nn.Linear(dim_input, dim_hidden),\n","            nn.Tanh(),\n","            nn.Linear(dim_hidden, dim_output),\n","            nn.Sigmoid())\n","\n","    def forward(self, state):\n","        \"\"\"Forward propagation.\n","\n","        Inputs:\n","          - state(torch.Tensor):  The system state of size [dim_input,]\n","        Returns:\n","          - action(torch.Tensor): The action to take of size [dim_output,]\n","        \"\"\"\n","        action = self.network(state)\n","        return action\n","\n","\n","class Rocket():\n","    def __init__(self, controller, T):\n","        \"\"\"Inputs:\n","          - controller(class): The rocket controller\n","          - T(int):            Number of simulation time steps\n","        \"\"\"\n","        self.init_state = self.initialize_state()\n","        self.controller = controller\n","        self.T = T\n","        self.action_trajectory = []\n","        self.state_trajectory = []\n","        self.beta = 0.3  # Drag coefficient\n","\n","    @staticmethod\n","    def initialize_state():\n","        state = [1., 0.]\n","        return t.tensor(state, requires_grad=False).float()\n","\n","    def dynamics(self, state, action):\n","        \"\"\"Rocket dynamics.\n","\n","        Inputs:\n","          - state(torch.Tensor):  The state of the system\n","                                  state[0] = y, state[1] = y_dot\n","          - action(torch.Tensor): Amount of Thrust\n","        Returns:\n","          - state(torch.Tensor):  The state of the system at the next time step, after taking the action\n","        \"\"\"\n","\n","        A = t.tensor([[1., FRAME_TIME-1/2*self.beta*FRAME_TIME**2],\n","                      [0., 1-self.beta*FRAME_TIME]])\n","        B = t.tensor([-1/2*FRAME_TIME**2, -FRAME_TIME])\n","        U = BOOST_ACCEL*action                     # Thrust\n","        G = t.tensor([1/2*FRAME_TIME**2, FRAME_TIME])*GRAVITY_ACCEL\n","        state = t.matmul(A, state) + B*U + G       # X[t+1] = AX[t] + BU[t] + G\n","        return state\n","\n","    def simulate_path(self, state):\n","        \"\"\"Rocket path simulation.\n","\n","        Inputs:\n","          - state(torch.Tensor):  The initial state of the system\n","        Returns:\n","          - state(torch.Tensor):  The state of the system at the last time step\n","        \"\"\"\n","        self.action_trajectory = []\n","        self.state_trajectory = []\n","        for _ in range(T):\n","            action = self.controller(state)\n","            state = self.dynamics(state, action)\n","            self.action_trajectory.append(action)\n","            self.state_trajectory.append(state)\n","        return state  # Final state of rocket\n","\n","\n","class Optimize:\n","    \"\"\"Optimizer that trains the Controller.\"\"\"\n","    def __init__(self, rocket):\n","        self.rocket = rocket\n","        self.parameters = rocket.controller.parameters()\n","        self.optimizer = optim.LBFGS(self.parameters, lr=0.01)\n","        # self.optimizer = optim.Adagrad(self.parameters, lr=0.65)\n","        self.eps = 1e-7  # Loss value threshold to stop training\n","\n","    def loss_fun(self, state):\n","        \"\"\"The loss function\n","\n","        Inputs:\n","          - state(torch.Tensor):  The final state of the system\n","        \"\"\"\n","        return state[0]**2 + state[1]**2\n","\n","    def train(self, network, epochs):\n","        \"\"\"Trains the model/controller.\n","\n","        Inputs:\n","          - network(class): The controller\n","          - epochs(int):    The number of training iterations\n","        \"\"\"\n","\n","        network.train()  # Set the module in training mode (only affects certain modules)\n","        epoch = 0\n","        loss = float('inf')\n","\n","        while loss > self.eps and epoch < epochs:\n","\n","            def closure():\n","                \"\"\"A closure that reevaluates the model and returns the loss.\n","                Needed for some optimizers like LBFGS. \"\"\"\n","                self.optimizer.zero_grad()                                  # Clear gradients\n","                final_state = self.rocket.simulate_path(self.rocket.init_state)  # Compute final state\n","                loss = self.loss_fun(final_state)                           # Compute loss\n","                loss.backward()                                             # Compute gradients\n","                return loss\n","\n","            self.optimizer.step(closure)                                    # Update weights\n","            loss = closure()                                                # Compute loss\n","\n","            epoch += 1\n","            print('Epoch: {} \\t Loss: {:.6}'.format(epoch, loss))\n","            print('Final state: {}'.format(self.rocket.simulate_path(self.rocket.init_state).detach().numpy()))\n","            self.visualize()\n","\n","    def visualize(self):\n","        \"\"\"Plots rocket path and trajectories.\"\"\"\n","\n","        data = np.array([self.rocket.state_trajectory[i].detach().numpy() for i in range(self.rocket.T)])\n","        x = data[:, 0]  # Distance from ground\n","        v = data[:, 1]  # Velocity\n","\n","        sns.set_theme()\n","        fig = plt.figure(figsize=(20, 6))\n","        \n","        # Distance vs Velocity\n","        ax = fig.add_subplot(1, 3, 1)\n","        ax.plot(x, v)\n","        ax.plot(x[0], v[0], 'o', label='initial state')\n","        ax.legend(loc='upper center')\n","        ax.set_xlabel('Distance from ground')\n","        ax.set_ylabel('Velocity')\n","        ax.set_title('State Path')\n","        \n","        # Time vs Distance\n","        ax = fig.add_subplot(1, 3, 2)        \n","        ax.plot(x)\n","        ax.plot(0, x[0], 'o', label='initial state')\n","        ax.legend(loc='upper center')\n","        ax.set_xlabel('Time')\n","        ax.set_ylabel('Distance from ground')\n","        ax.set_title('Rocket Trajectory')\n","        \n","        # Time vs Velocity\n","        ax = fig.add_subplot(1, 3, 3)\n","        ax.plot(v)\n","        ax.plot(0, v[0], 'o', label='initial state')\n","        ax.legend(loc='upper center')\n","        ax.set_xlabel('Time')\n","        ax.set_ylabel('Velocity')\n","        ax.set_title('Rocket Trajectory')\n","        plt.show()\n","        \n","        # ax.plot(np.zeros(len(x)), x, 'o')\n","        # ax.set_xlabel('x')\n","        # ax.set_ylabel('Distance from ground d')\n","        # ax.set_title('Rocket Position')\n","\n","\n","if __name__ == \"__main__\":\n","\n","    # Environment parameters\n","    # -------------------------------------------------------------------------\n","    FRAME_TIME = 0.1                                   # Time interval Dt\n","    GRAVITY_ACCEL = 0.12                               # Gravity constant\n","    BOOST_ACCEL = 0.18                                 # Thrust constant\n","\n","    # Training parameters\n","    # -------------------------------------------------------------------------\n","    T = 100                                            # Number of time steps the rocket is simulated\n","    dim_input = 2                                      # State space dimensions\n","    dim_hidden = 6                                     # Latent dimensions\n","    dim_output = 1                                     # Action space dimensions\n","\n","    # Optimize Rocket Controller\n","    # -------------------------------------------------------------------------\n","    c = Controller(dim_input, dim_hidden, dim_output)  # Define controller\n","    s = Rocket(c, T)                                   # Define rocket simulation\n","    o = Optimize(s)                                    # Define optimizer\n","    o.train(c, 100)                                    # Solve the optimization problem\n"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"eAmf3vUwUrgV"},"source":[""],"execution_count":null,"outputs":[]}]}