{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"DesignOptimization_HW_2.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"DY-XwFeWp7Eg"},"source":["# Theory/Computation Problems\n","\n","### Problem 1 (20 points) \n","Show that the stationary point (zero gradient) of the function\n","$$\n","\\begin{aligned}\n","    f=2x_{1}^{2} - 4x_1 x_2+ 1.5x^{2}_{2}+ x_2\n","\\end{aligned}\n","$$\n","is a saddle (with indefinite Hessian). Find the directions of downslopes away from the saddle. Hint: Use Taylor's expansion at the saddle point. Find directions that reduce $f$."],"id":"DY-XwFeWp7Eg"},{"cell_type":"markdown","metadata":{"id":"wMnZVqSHqRBx"},"source":["#### Solution \n","\n","$$f(x)=2x_1^2 - 4x_1 x_2+ 1.5x^2_2+ x_2$$\n","\n","The gradient of the function $f(x)$ is: \n","\n","$$g(x)=\\nabla f(x)=\n","    \\begin{bmatrix}\n","    \\frac{\\partial f}{\\partial x_1}\\\\\\\\\n","    \\frac{\\partial f}{\\partial x_2}\n","    \\end{bmatrix}\n","    =\n","    \\begin{bmatrix}\n","    4x_1-4x_2\\\\\\\\\n","    -4x_1+3x_2+1\n","    \\end{bmatrix}\n","$$\n","\n","Let $x^\\star$ be a stationary point of $f(x)$. Then, $x^\\star$ satisfies the\n","equation $g(x^\\star)=0$.\n","\n","$$\\Rightarrow \n","    g(x^\\star)=\n","    \\begin{bmatrix}\n","    4x_1-4x_2\\\\\\\\\n","    -4x_1+3x_2+1\n","    \\end{bmatrix}\n","    =\n","    \\begin{bmatrix}\n","    0\\\\\\\\\n","    0\n","    \\end{bmatrix}\n","$$\n","\n","<br>\n","$$\\Rightarrow \n","  \\begin{equation*}\n","  \\left\\{\\begin{aligned}\n","    4x_1-4x_2=0\\\\\n","    -4x_1+3x_2+1=0\n","  \\end{aligned}\n","  \\right.\\end{equation*} \n","$$\n","\n","<br>\n","$$\\Rightarrow \n","  \\begin{equation*}\n","  \\left\\{\\begin{aligned}\n","    x_1 &=x_2\\\\\n","    -4x_1+3x_1+1 &=0\n","  \\end{aligned}\n","  \\right.\\end{equation*} \n","$$\n","\n","<br>\n","$$\\begin{aligned}\n","  \\Rightarrow x_1=1=x_2\\\\\n","  \\Rightarrow x^\\star=\n","  \\begin{bmatrix}\n","    1\\\\\n","    1\n","  \\end{bmatrix}\\end{aligned}\n","$$\n","\n","\n","<br> \n","The Hessian matrix of $f(x)$ is:\n","\n","$$\\begin{aligned}\n","  H(x)=\\nabla ^2f(x)=\n","  \\begin{bmatrix}\n","    \\frac{\\partial ^2 f}{\\partial x_1^2} && \\frac{\\partial ^2 f}{\\partial x_1\\partial x_2}\\\\\\\\\n","    \\frac{\\partial ^2 f}{\\partial x_2\\partial x_1} && \\frac{\\partial ^2 f}{\\partial x_2^2}\n","  \\end{bmatrix}\n","  =\n","  \\begin{bmatrix}\n","    4 && -4\\\\\\\\\n","    -4 && 3\n","  \\end{bmatrix}\\end{aligned}\n","$$\n","\n","and $H(x^\\star)= \n","  \\begin{bmatrix}\n","    4 && -4\\\\\\\\\n","    -4 && 3\n","  \\end{bmatrix}$.\n","\n","<br> \n","We have that: <br> \n","$$|H(x)|=\\lambda_1 \\cdot \\lambda_2$$ \n","and also: <br> \n"," $$\\begin{aligned}\n","    |H(x)|=3\\cdot 4-(-4)\\cdot (-4)=12-16=-4<0\n","    \\end{aligned}\n"," $$\n","\n","$\\Rightarrow \\lambda_1,\\lambda_2$ have opposite signs. Hence, the matrix\n","$H(x)$ is indefinite and therefore, the stationary point is a **saddle point**. \n","\n","\n","<br />\n","The 2nd-order Taylor Series approximation of the function is:\n","$$f(x)\\approx f(x^\\star)+g^T(x^\\star)(x-x^\\star)+\\frac{1}{2}(x-x^\\star)^TH(x^\\star)(x-x^\\star)$$\n","\n","where \n","\n","$f(x^\\star)=2\\cdot 1^2-4\\cdot 1\\cdot 1+1.5\\cdot 1^2+1=0.5$\n","<br>\n","$g(x^\\star)=0$\n","\n","$$\\Rightarrow f(x)\\approx 0.5+\\frac{1}{2} \n","  \\begin{bmatrix}\n","    x_1-1 && x_2-1\n","  \\end{bmatrix} \n","  \\begin{bmatrix}\n","    4 && -4\\\\\\\\\n","    -4 && 3\n","  \\end{bmatrix}\n","  \\begin{bmatrix}\n","    x_1-1 \\\\\\\\\n","    x_2-1\n","  \\end{bmatrix}\n","  =2x_1^2 - 4x_1 x_2+ 1.5x^2_2+ x_2\n","$$\n","\n","\n","At the saddle point, in the directions that $f$ reduces, we have that \n","$f(x)< f(x^\\star)$.\n","\n","$$\\Rightarrow f(x)-f(x^\\star)< 0 $$\n","$$\\Rightarrow \\frac{1}{2}(x-x^\\star)^TH(x^\\star)(x-x^\\star)< 0 $$\n","$$\\Rightarrow (x-x^\\star)^TH(x^\\star)(x-x^\\star)< 0 $$\n","$$\\Rightarrow 4x_1^2 - 8x_1 x_2+ 3x^2_2+ 2x_2 -1< 0 $$\n","$$\\Rightarrow (2x_1-3x_2+1)(2x_1-x_2-1)< 0 $$\n","\n","\n","which means that $f$ reduces when:\n","\n","$$(2x_1-3x_2+1)>0  \\ and\\ (2x_1-x_2-1)< 0 $$\n","or\n","$$(2x_1-3x_2+1)< 0 \\ and\\ (2x_1-x_2-1)> 0 $$\n","\n","\n","\n","More specifically, the eigenvalues of the Hessian are:\n"],"id":"wMnZVqSHqRBx"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvUsr__GRlWl","executionInfo":{"status":"ok","timestamp":1631362192765,"user_tz":-180,"elapsed":360,"user":{"displayName":"Elena Oikonomou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjieaR8SwyW3oT5Gj_-eTKl6SVjziMwjwjye6=s64","userId":"03571600125738632827"}},"outputId":"4ae48e7b-1d15-4e61-9b75-cb43b8985933"},"source":["import numpy as np\n","from numpy import linalg as LA\n","\n","H = np.array([[4, -4], [-4, 3]])  # Hessian\n","w,v = LA.eig(H)                   # Eigenvalues and eigenvectors \n","print(\"The eigenvalues are: {}\".format(w))\n","print(\"The eigenvectors are:\\n {}\".format(v))"],"id":"vvUsr__GRlWl","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The eigenvalues are: [ 7.53112887 -0.53112887]\n","The eigenvectors are:\n"," [[ 0.74967818  0.66180256]\n"," [-0.66180256  0.74967818]]\n"]}]},{"cell_type":"markdown","metadata":{"id":"v-fMjQEPTNZL"},"source":["$\\lambda_1=7.53112887, \\lambda_2=-0.53112887$\n","\n","The direction of downslope, where the function curves down, is the principal direction which corresponds to the negative eigenvalue. This is:\n","\n","$$v_2=\\begin{bmatrix}\n","    -0.66180256\\\\\\\\\n","    0.74967818\n","  \\end{bmatrix}$$"],"id":"v-fMjQEPTNZL"},{"cell_type":"markdown","metadata":{"id":"xXLxSnH8dLAj"},"source":["### Problem 2 (50 points) \n","\n","* (10 points) Find the point in the plane $x_1+2x_2+3x_3=1$ in $\\mathbb{R}^3$ that is nearest to the point $(-1,0,1)^T$. Is this a convex problem? Hint: Convert the problem into an unconstrained problem using $x_1+2x_2+3x_3=1$.\n","\n","* (40 points) Implement the gradient descent and Newton's algorithm for solving the problem. Attach your codes along with a short summary including (1) the initial points tested, (2) corresponding solutions, (3) a log-linear convergence plot."],"id":"xXLxSnH8dLAj"},{"cell_type":"markdown","metadata":{"id":"Z7bocA9ydSfW"},"source":["#### Solution\n","\n","i) If we let \n","$w=\\begin{bmatrix}\n","    x_1 & x_2 & x_3\n","  \\end{bmatrix}^T$\n","be any point on the plane and \n","$x_0=\\begin{bmatrix}\n","    -1 & 0 & 1\n","  \\end{bmatrix}^T$\n","be the given point of interest, then the vector\n","\n","$$z=\\begin{bmatrix}\n","    x_1-(-1)\\\\\\\\ \n","    x_2-0\\\\\\\\\n","    x_3-1\n","  \\end{bmatrix}\n","  =\n","  \\begin{bmatrix}\n","    x_1+1\\\\\\\\ \n","    x_2\\\\\\\\\n","    x_3-1\n","  \\end{bmatrix}\n","$$\n","\n","denotes the distance between them. The point $w$ that is nearest to $x_0$ is the one with the smallest distance, i.e. whose vector $z$ length is minimum.\n","The length of the vector $z$ is:\n","$$|z|=\\sqrt{(x_1+1)^2+(x_2)^2+(x_3-1)^2}$$\n","<br>\n","Therefore, we need to find the solution to the following minimization problem: \n","\n","$$\n","\\begin{aligned}\n","&\\underset{x_1,x_2,x_3}{\\text{minimize:}} && (x_1+1)^2+(x_2)^2+(x_3-1)^2 \\\\\\\\\n","&\\text{subject to:} && x_1+2x_2+3x_3=1 \\\\\\\\\n","&&& x_i \\in \\Re, \\ i=1,2,3\n","\\end{aligned}\n","$$\n","\n","<br>\n","If we let $x_1=-2x_2-3x_3+1$, we have that:\n","$$\n","(x_1+1)^2+(x_2)^2+(x_3-1)^2 = (2-2x_2-3x_3)^2+(x_2)^2+(x_3-1)^2\n","$$\n","\n","and we can convert the problem to the following unconstrained optimization problem:\n","\n","$$\n","\\underset{x_2,x_3}{\\text{minimize: }}  f(x)=(2-2x_2-3x_3)^2+(x_2)^2+(x_3-1)^2 \n","$$\n","\n","The solution to the minimization problem is:"],"id":"Z7bocA9ydSfW"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oj4XkGisAm-b","executionInfo":{"status":"ok","timestamp":1631367029044,"user_tz":-180,"elapsed":311,"user":{"displayName":"Elena Oikonomou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjieaR8SwyW3oT5Gj_-eTKl6SVjziMwjwjye6=s64","userId":"03571600125738632827"}},"outputId":"86e60f2f-7a51-40f4-b07f-f86c7fb51463"},"source":["from scipy.optimize import minimize\n","\n","# Objective function\n","fun = lambda x: (2-2*x[0]-3*x[1])**2 + (x[0])**2 + (x[1]-1)**2\n","\n","# Initial guess\n","x0 = (1, 0)\n","\n","# Optimization Result\n","res = minimize(fun, x0, method='SLSQP')\n","\n","# Function value\n","print('Function value: f = {}'.format(res.fun))\n","\n","# Variable values \n","print('Variable values:\\nx2, x3 = {}, {}'.format(res.x[0], res.x[1]))\n","\n","# Compute x1\n","x1=-2*res.x[0]-3*res.x[1]+1\n","print(\"x1 = {}\".format(x1))"],"id":"Oj4XkGisAm-b","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Function value: f = 0.07142857142857148\n","Variable values:\n","x2, x3 = -0.14285713906428532, 0.7857142823269022\n","x1 = -1.071428568852136\n"]}]},{"cell_type":"markdown","metadata":{"id":"tujTkKJ8B8Zz"},"source":["Therefore, the point in the plane that is nearest to $x_0$ is: \n","$w=\\begin{bmatrix}\n","    x_1 & x_2 & x_3\n","  \\end{bmatrix}^T\n","  =\n","  \\begin{bmatrix}\n","    -1.071428 & -0.142857 & 0.785714\n","  \\end{bmatrix}^T $\n","\n","The gradient of $f(x)$ is:\n","$$g(x)=\\nabla f(x)=\n","    \\begin{bmatrix}\n","    10x_2+12x_3-8\\\\\\\\\n","    12x_2+20x_3-14\n","    \\end{bmatrix}\n","$$\n","\n","The Hessian is:\n","$$\\begin{aligned}\n","  H(x)=\\nabla ^2f(x)=\n","  \\begin{bmatrix}\n","    10 && 12\\\\\\\\\n","    12 && 20\n","  \\end{bmatrix}\\end{aligned}\n","$$\n"],"id":"tujTkKJ8B8Zz"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlBbs3WsHl-C","executionInfo":{"status":"ok","timestamp":1631368191470,"user_tz":-180,"elapsed":443,"user":{"displayName":"Elena Oikonomou","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdjieaR8SwyW3oT5Gj_-eTKl6SVjziMwjwjye6=s64","userId":"03571600125738632827"}},"outputId":"365854c0-b097-42cc-b3d8-f3aedb4b94c9"},"source":["import numpy as np\n","from numpy import linalg as LA\n","\n","H = np.array([[10, 12], [12, 20]])  # Hessian\n","w,v = LA.eig(H)                     # Eigenvalues and eigenvectors \n","print(\"The eigenvalues are: {}\".format(w))"],"id":"vlBbs3WsHl-C","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["The eigenvalues are: [ 2. 28.]\n"]}]},{"cell_type":"markdown","metadata":{"id":"m7CZHzCcH1k4"},"source":["The eigenvalues are all positive, hence the Hessian is positive definite everywhere. Therefore, $f(x)$ and thus the unconstrained optimization problem are convex.\n","\n","<br>\n","ii)"],"id":"m7CZHzCcH1k4"},{"cell_type":"markdown","metadata":{"id":"touched-logic"},"source":["\n","\n","### Problem 3 (10 points) \n","Let $f(x)$ and $g(x)$ be two convex functions defined on the convex set $\\mathcal{X}$. \n","* (5 points) Prove that $af(x)+bg(x)$ is convex for $a>0$ and $b>0$. \n","* (5 points) In what conditions will $f(g(x))$ be convex?\n","\n","### Problem 4 (bonus 10 points)\n","Show that $f({\\bf x}_1) \\geq f(\\textbf{x}_0) + \n","    \\textbf{g}_{\\textbf{x}_0}^T(\\textbf{x}_1-\\textbf{x}_0)$ for a convex function $f(\\textbf{x}): \\mathcal{X} \\rightarrow \\mathbb{R}$ and for $\\textbf{x}_0$, $\\textbf{x}_1 \\in \\mathcal{X} \n","$. "],"id":"touched-logic"},{"cell_type":"markdown","metadata":{"id":"collected-carbon"},"source":["# Design Problems\n","\n","### Problem 5 (20 points) \n","Consider an illumination problem: There are $n$ lamps and $m$ mirrors fixed to the ground. The target reflection intensity level is $I_t$. The actual reflection intensity level on the $k$th mirror can be computed as $\\textbf{a}_k^T \\textbf{p}$, where $\\textbf{a}_k$ is given by the distances between all lamps to the mirror, and $\\textbf{p}:=[p_1,...,p_n]^T$ are the power output of the lamps. The objective is to keep the actual intensity levels as close to the target as possible by tuning the power output $\\textbf{p}$.\n","\n","* (5 points) Formulate this problem as an optimization problem. \n","* (5 points) Is your problem convex?\n","* (5 points) If we require the overall power output of any of the $n$ lamps to be less than $p^*$, will the problem have a unique solution?\n","* (5 points) If we require no more than half of the lamps to be switched on, will the problem have a unique solution?"],"id":"collected-carbon"},{"cell_type":"markdown","metadata":{"id":"moderate-twins"},"source":["# Note\n","\n","For this homework, you may want to attach sketches as means to explain your ideas. Here is how you can attach images.\n","\n","![everly1](img/everly7.jpg)"],"id":"moderate-twins"}]}